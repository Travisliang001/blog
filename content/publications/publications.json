[
    {
        "title": "SHARP Challenge 2023: Solving CAD History and pArameters Recovery from Point clouds and 3D scans. Overview, Datasets, Metrics, and Baselines",
        "authors": " Dimitrios Mallis, Sk Aziz Ali, Elona Dupont, Kseniya Cherenkova, Ahmet Serdar Karadeniz, Mohammad Sadil Khan, Anis Kacem, Gleb Gusev, Djamila Aouada",
        "conference": "ICCV Workshop 2023",
        "year": 2023,
        "codeLink": "https://gitlab.uni.lu/cvi2/iccv2023-sharp-challenge",
        "poster": "https://skazizali.com/assets/pdf/SHARP_ICCV23_Poster.pdf",
        "bibtex": "@inproceedings{AliSHARP_ICCV23,title = {SHARP Challenge 2023: Solving CAD History and pArameters Recovery from Point clouds and 3D scans. Overview, Datasets, Metrics, and Baselines},author = {Mallis, Dimitrios and Ali, Sk Aziz and Dupont, Elona and Cherenkova, Kseniya and Karadeniz, Ahmet Serdar and Kacem, Mohammed Sadil Khan Anis and Gusev, Gleb and Aouada, Djamila},booktitle = {In IEEE/CVF International Conference on Computer Vision (ICCV)},year = {2023},organization = {IEEE},}",
        "arxiv": "https://arxiv.org/abs/2308.07153",
        "dataset": "Recent breakthroughs in geometric Deep Learning (DL) and the availability of large Computer-Aided Design (CAD) datasets have advanced the research on learning CAD modeling processes and relating them to real objects. In this context, 3D reverse engineering of CAD models from 3D scans is considered to be one of the most sought-after goals for the CAD industry. However, recent efforts assume multiple simplifications limiting the applications in real-world settings. The SHARP Challenge 2023 aims at pushing the research a step closer to the real-world scenario of CAD reverse engineering through dedicated datasets and tracks. In this paper, we define the proposed SHARP 2023 tracks, describe the provided datasets, and propose a set of baseline methods along with suitable evaluation metrics to assess the performance of the track solutions. All proposed datasets along with useful routines and the evaluation metrics are publicly available. ",
        "paperLink": "https://paperswithcode.com/paper/sharp-challenge-2023-solving-cad-history-and",
        "categories": "Deep Learning, Computer Vision, Representation Learning, CAD",
        "image": "data/sharp2023.png",
         "metadata": "",
         "video": ""
    },
    {
        "title": "MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation",
        "authors": "Sankalp Sinha*, Mohammad Sadil Khan*, Muhammad Usama, Shino Sam, Didier Stricker, Sk Aziz Ali, Muhammad Zeshan Afzal",
        "conference": "Preprint (Arxiv)",
        "year": 2025,
        "project": "",
        "codeLink": "",
        "poster": "",
        "bibtex": "@misc{sinha2024marvel40mmultilevelvisualelaboration,title={MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation}, author={Sankalp Sinha and Mohammad Sadil Khan and Muhammad Usama and Shino Sam and Didier Stricker and Sk Aziz Ali and Muhammad Zeshan Afzal},year={2024}, eprint={2411.17945},archivePrefix={arXiv}, primaryClass={cs.CV}, url={https://arxiv.org/abs/2411.17945}, }",
        "arxiv": "https://arxiv.org/abs/2411.17945",
        "video": "",
        "dataset": "",
        "paperLink": "",
        "categories": "Text-to-3D, Stable Diffusion, 3D Reconstruction, LLM, VLM, Annotation, Objaverse",
        "image": "data/marvel.png",
        "metadata": "The largest and the most descriptive 3D Captioning Dataset."
    },
    {
        "title": "Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts",
        "authors": "Mohammad Sadil Khan*, Sankalp Sinha*, Sheikh Talha Uddin, Didier Stricker, Sk Aziz Ali, Muhammad Zeshan Afzal",
        "conference": "NeurIPS 2024 (Spotlight)",
        "year": 2024,
        "project": "https://sadilkhan.github.io/text2cad-project/",
        "codeLink": "https://github.com/SadilKhan/Text2CAD",
        "poster": "https://neurips.cc/media/PosterPDFs/NeurIPS%202024/96571.png?t=1731322691.2308366",
        "bibtex": "@inproceedings{khan2024textcad,title={Text2{CAD}: Generating Sequential {CAD} Designs from Beginner-to-Expert Level Text Prompts},author={Mohammad Sadil Khan and Sankalp Sinha and Sheikh Talha Uddin and Didier Stricker and Sk Aziz Ali and Muhammad Zeshan Afzal},booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},year={2024},url={https://openreview.net/forum?id=5k9XeHIK3L}}",
        "arxiv": "https://arxiv.org/abs/2409.17106",
        "video": "",
        "dataset": "https://huggingface.co/datasets/SadilKhan/Text2CAD",
        "paperLink": "https://openreview.net/pdf?id=5k9XeHIK3L",
        "categories": "Deep Learning, Computer Vision, Point Cloud, Representation Learning, Text, LLM, VLM, CAD, Vision-Language Modeling, Annotation",
        "image": "data/text2cad.png",
        "metadata": "An AI framework to generate CAD design history from Multi-Level text prompts."
    },
    {
        "title": "BRep Boundary and Junction Detection for CAD Reverse Engineering",
        "authors": " Sk Aziz Ali, Mohammad Sadil Khan, Didier Stricker",
        "conference": "ICMI 2024",
        "year": 2024,
        "codeLink": "https://github.com/saali14/Scan-to-BRep",
        "project": "https://skazizali.com/brepdetnet.github.io/",
        "poster": "",
        "bibtex": "@INPROCEEDINGS{10585950,author={Ali, Sk Aziz and Khan, Mohammad Sadil and Stricker, Didier},booktitle={2024 IEEE 3rd International Conference on Computing and Machine Intelligence (ICMI)}, title={BRep Boundary and Junction Detection for CAD Reverse Engineering}, year={2024},volume={},number={},pages={1-6},keywords={Training;Solid modeling;Three-dimensional displays;Reverse engineering;Neural networks;Machining;Mechanical systems;BRep;Boundary Detection;Junction Detection;Scan-to-CAD;Reverse Engineering;NMS},doi={10.1109/ICMI60790.2024.10585950}}",
        "arxiv": "https://www.semanticscholar.org/paper/BRep-Boundary-and-Junction-Detection-for-CAD-Ali-Khan/cadccf40d3a254114c75e7c7ab390a0f8ad0bcda",
        "dataset": "",
        "paperLink": "https://ieeexplore.ieee.org/document/10585950",
        "categories": "Deep Learning, Computer Vision, CAD, Brep",
        "image": "data/brep_det_net.png",
         "metadata": "",
         "video": ""
    },
    {
        "title": "CAD-SIGNet: CAD Language Inference from Point Clouds using Layer-wise Sketch Instance Guided Attention",
        "authors": "Mohammad Sadil Khan, Elona Dupont, Sk Aziz Ali, Kseniya Cherenkova, Anis Kacem, Djamila Aouada",
        "conference": "CVPR 2024 (Highlight - Top 12%)",
        "year": 2024,
        "project": "http://skazizali.com/cadsignet.github.io/",
        "codeLink": "",
        "poster": "https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30538.png?t=1716992823.610076",
        "bibtex": "@InProceedings{{Khan_2024_CVPR,author = {Khan, Mohammad Sadil and Dupont, Elona and Ali, Sk Aziz and Cherenkova, Kseniya and Kacem, Anis and Aouada, Djamila}, title = {CAD-SIGNet: CAD Language Inference from Point Clouds using Layer-wise Sketch Instance Guided Attention}, booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},month = {June},year = {2024},pages = {4713-4722}}",
        "arxiv": "https://arxiv.org/pdf/2402.17678.pdf",
        "video": "https://www.youtube.com/watch?v=ivg03_ckLIM",
        "dataset": "",
        "paperLink": "https://openaccess.thecvf.com/content/CVPR2024/papers/Khan_CAD-SIGNet_CAD_Language_Inference_from_Point_Clouds_using_Layer-wise_Sketch_CVPR_2024_paper.pdf",
        "categories": "Deep Learning, Computer Vision, Point Cloud, Representation Learning, RandLa-Net, CAD, Vision-Language Modeling",
        "image": "data/cad_signet.png",
        "metadata": "An autoregressive architecture for generating CAD sequence from Point cloud."
    }
    
]
